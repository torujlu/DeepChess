{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing ANNs with TensorFlow\n",
    "# Final Project: Chess Playing Environment for DeepChess\n",
    "# Group 12: Renato Garita Figueiredo, Hamza Kebiri, Turan Orujlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import chess\n",
    "import chess.svg\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepChess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepChessData(object):\n",
    "    \n",
    "    def __init__(self, win_file, loss_file):\n",
    "        \n",
    "        win_data = np.load(win_file)['arr_0']\n",
    "        loss_data = np.load(loss_file)['arr_0']\n",
    "        \n",
    "        # Small value to avoid zero division\n",
    "        epsilon = 1e-9\n",
    "        \n",
    "        # Take win data samples for population moments calculation\n",
    "        # It is computationally expensive to do it for the full data\n",
    "        np.random.seed(0)\n",
    "        indices_w = np.random.choice(len(win_data), size = 250000, replace = False)\n",
    "        win_samples = win_data[indices_w]\n",
    "        \n",
    "        # Clean the cache\n",
    "        del win_data\n",
    "        del indices_w\n",
    "        \n",
    "        # Take loss data samples for population moments calculation\n",
    "        # It is computationally expensive to do it for the full data\n",
    "        np.random.seed(1)\n",
    "        indices_l = np.random.choice(len(loss_data), size = 250000, replace = False)\n",
    "        loss_samples = loss_data[indices_l]\n",
    "        \n",
    "        # Clean the cache\n",
    "        del loss_data\n",
    "        del indices_l\n",
    "        \n",
    "        # Combine win and loss samples\n",
    "        samples = np.concatenate((win_samples, loss_samples))\n",
    "        \n",
    "        # Clean the cache\n",
    "        del win_samples\n",
    "        del loss_samples\n",
    "        \n",
    "        # Calculate population moments\n",
    "        self.avg = np.mean(samples, 0)\n",
    "        self.std = np.std(samples, 0) + epsilon\n",
    "        \n",
    "        # Clean the cache\n",
    "        del samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class that defines the behavior of an Autoencoder\n",
    "class Autoencoder(object):\n",
    "    \n",
    "    # Encode input with input_size as an output with output_size\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        # Defining the hyperparameters\n",
    "        self.input_size = input_size # The input size\n",
    "        self.output_size = output_size # The output size\n",
    "        \n",
    "        # Training weights and biases\n",
    "        self.weights = {}\n",
    "        self.biases = {}\n",
    "        \n",
    "        # Encoder\n",
    "        with tf.variable_scope('encoder_vars'):\n",
    "            \n",
    "            # ReLU weights\n",
    "            var_init = tf.truncated_normal_initializer(stddev = 2 / input_size)\n",
    "            self.weights['encoder_h'] = tf.get_variable('encoder_h_' + str(input_size) + '_-_' + str(output_size),\n",
    "                                                        [input_size, output_size],\n",
    "                                                        tf.float32,\n",
    "                                                        var_init)\n",
    "            \n",
    "            # ReLU biases\n",
    "            var_init = tf.constant_initializer(0.01)\n",
    "            self.biases['encoder_b'] = tf.get_variable('encoder_b' + str(output_size),\n",
    "                                                       [output_size],\n",
    "                                                       tf.float32,\n",
    "                                                       var_init)\n",
    "        \n",
    "        # Decoder\n",
    "        with tf.variable_scope('decoder_vars'):\n",
    "\n",
    "            # ReLU weights\n",
    "            var_init = tf.truncated_normal_initializer(stddev = 2 / input_size)\n",
    "            self.weights['decoder_h'] = tf.get_variable('decoder_h' + str(output_size) + '_-_' + str(input_size),\n",
    "                                                        [output_size, input_size],\n",
    "                                                        tf.float32,\n",
    "                                                        var_init)\n",
    "            \n",
    "            # ReLU biases\n",
    "            var_init = tf.constant_initializer(0.01)\n",
    "            self.biases['decoder_b'] = tf.get_variable('decoder_b' + str(input_size),\n",
    "                                                       [input_size], \n",
    "                                                       tf.float32,\n",
    "                                                       var_init)\n",
    "    \n",
    "        # Input\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.input_size])\n",
    "        \n",
    "        # Stage indicator for batch normalization\n",
    "        self.is_training = tf.placeholder(tf.bool, None)\n",
    "\n",
    "        # Construct model\n",
    "        with tf.variable_scope('encoder_op'):\n",
    "            self.encoder_op = self.encoder(self.X, True)\n",
    "        with tf.variable_scope('decoder_op'):\n",
    "            decoder_op = self.decoder(self.encoder_op, True)\n",
    "\n",
    "        # Prediction\n",
    "        y_pred = decoder_op\n",
    "    \n",
    "    # Batch Normalization with population parameters (non-training)\n",
    "    def _pop_batch_norm(self, x, pop_mean, pop_var, offset, scale):\n",
    "            return tf.nn.batch_normalization(x, pop_mean, pop_var, offset, scale, 1e-6)\n",
    "\n",
    "    # Batch Normalization with batch parameters (training)\n",
    "    def _batch_norm(self, x, pop_mean, pop_var, mean, var, offset, scale):\n",
    "        decay = 0.99\n",
    "\n",
    "        dependency_1 = tf.assign(pop_mean, pop_mean * decay + mean * (1 - decay))\n",
    "        dependency_2 = tf.assign(pop_var, pop_var * decay + var * (1 - decay))\n",
    "\n",
    "        with tf.control_dependencies([dependency_1, dependency_2]):\n",
    "            return tf.nn.batch_normalization(x, mean, var, offset, scale, 1e-6)\n",
    "\n",
    "    # Batch Normalization\n",
    "    def _batch_normalize(self, x, axes):\n",
    "        depth = x.shape[-1]\n",
    "        mean, var = tf.nn.moments(x, axes = axes)\n",
    "\n",
    "        var_init = tf.constant_initializer(0.0)\n",
    "        offset = tf.get_variable('offset', [depth], tf.float32, var_init)\n",
    "        var_init = tf.constant_initializer(1.0)\n",
    "        scale = tf.get_variable('scale', [depth], tf.float32, var_init)\n",
    "\n",
    "        pop_mean = tf.get_variable('pop_mean', [depth], initializer = tf.zeros_initializer(), trainable = False)\n",
    "        pop_var = tf.get_variable('pop_var', [depth], initializer = tf.ones_initializer(), trainable = False)\n",
    "\n",
    "        return tf.cond(\n",
    "            self.is_training,\n",
    "            lambda: self._batch_norm(x, pop_mean, pop_var, mean, var, offset, scale),\n",
    "            lambda: self._pop_batch_norm(x, pop_mean, pop_var, offset, scale)\n",
    "        )\n",
    "    \n",
    "    # Building the encoder: encode the input with ReLU activation\n",
    "    def encoder(self, x, normalize = False):\n",
    "\n",
    "        activation = tf.add(tf.matmul(x, self.weights['encoder_h']), self.biases['encoder_b'])\n",
    "\n",
    "        # Batch Normalization\n",
    "        if normalize:\n",
    "            activation = self._batch_normalize(activation, [0])\n",
    "\n",
    "        return tf.nn.relu(activation)\n",
    "\n",
    "    # Building the decoder: decode the input with ReLU activation\n",
    "    def decoder(self, x, normalize = False):\n",
    "\n",
    "        activation = tf.add(tf.matmul(x, self.weights['decoder_h']), self.biases['decoder_b'])\n",
    "\n",
    "        # Batch Normalization\n",
    "        if normalize:\n",
    "            activation = self._batch_normalize(activation, [0])\n",
    "\n",
    "        return tf.nn.relu(activation)\n",
    "    \n",
    "    # Encoder output method for the Deep Belief Network\n",
    "    def encoder_output(self, sess, X):\n",
    "        \n",
    "        return sess.run(self.encoder_op, feed_dict = {self.X: X, self.is_training: False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Belief Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class that defines the behavior of a Deep Belief Network\n",
    "class DeepBeliefNetwork(object):\n",
    "    \n",
    "    # Create layers of Autoencoders with sizes dbn_layer_sizes\n",
    "    def __init__(self, dbn_layer_sizes):\n",
    "        \n",
    "        print(\"Initializing the Deep Belief Network Data Flow Graph ...\")\n",
    "        \n",
    "        # Create list to hold the Autoencoders\n",
    "        self.autoencoders = []\n",
    "        \n",
    "        # For each Autoencoder we want to generate\n",
    "        for i in range(len(dbn_layer_sizes) - 1):\n",
    "            with tf.variable_scope('Autoencoder_' + str(i + 1)):\n",
    "                input_size = dbn_layer_sizes[i]\n",
    "                output_size = dbn_layer_sizes[i + 1]\n",
    "                print(\"Autoencoder \", i + 1, \": \", input_size, \"->\", output_size, \"->\", input_size)\n",
    "                self.autoencoders.append(Autoencoder(input_size, output_size))\n",
    "                \n",
    "        print(\"The Deep Belief Network Data Flow Graph is initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class that defines the behavior of a Siamese Network\n",
    "class SiameseNetwork(object):\n",
    "    \n",
    "    # Stack fin_layer_sizes on top of a pair of deep_belief_network\n",
    "    def __init__(self, deep_belief_network, fin_layer_sizes):\n",
    "        \n",
    "        print(\"Initializing the Siamese Network Data Flow Graph ...\")\n",
    "        \n",
    "        # List to hold stage indicators for batch normalization in the Deep Belief Network\n",
    "        self.is_training_list = []\n",
    "        \n",
    "        # Deep Belief Network\n",
    "        for i, autoencoder in enumerate(deep_belief_network.autoencoders):\n",
    "            print(\"DBN Layer \", i + 1, \": \", autoencoder.input_size, \"->\", autoencoder.output_size)\n",
    "            self.is_training_list.append(autoencoder.is_training)\n",
    "            \n",
    "        # Training weights and biases\n",
    "        self.fin_weights = []\n",
    "        self.fin_biases = []\n",
    "        \n",
    "        # Final layers\n",
    "        with tf.variable_scope('final_layers'):\n",
    "\n",
    "            input_size = 2 * autoencoder.output_size\n",
    "            for i, fin_layer_size in enumerate(fin_layer_sizes):\n",
    "                output_size = fin_layer_size\n",
    "                \n",
    "                # ReLU weights\n",
    "                var_init = tf.truncated_normal_initializer(stddev = 2 / input_size)\n",
    "                \n",
    "                # Non-ReLU weights for the last layer\n",
    "                if (i == len(fin_layer_sizes) - 1):\n",
    "                    var_init = tf.truncated_normal_initializer(stddev = input_size ** (-1/2))                    \n",
    "                \n",
    "                self.fin_weights.append(tf.get_variable('fin_weights_' + str(i) + '_' + str(input_size) + '_-_' + str(output_size),\n",
    "                                                        [input_size, output_size],\n",
    "                                                        tf.float32,\n",
    "                                                        var_init))\n",
    "                \n",
    "                # ReLU biases\n",
    "                var_init = tf.constant_initializer(0.01)\n",
    "                \n",
    "                # Non-ReLU biases for the last layer\n",
    "                if (i == len(fin_layer_sizes) - 1):\n",
    "                    var_init = tf.constant_initializer(0.0)\n",
    "                \n",
    "                self.fin_biases.append(tf.get_variable('fin_biases_' + str(i) + '_' + str(output_size),\n",
    "                                                       [output_size],\n",
    "                                                       tf.float32,\n",
    "                                                       var_init))\n",
    "                \n",
    "                print(\"Final Layer \", i + 1, \": \", input_size, \"->\", output_size)\n",
    "                input_size = output_size\n",
    "            \n",
    "        # First and second inputs\n",
    "        self.X1 = tf.placeholder(tf.float32, [None, deep_belief_network.autoencoders[0].input_size])\n",
    "        self.X2 = tf.placeholder(tf.float32, [None, deep_belief_network.autoencoders[0].input_size])\n",
    "        \n",
    "        # Stage indicator for batch normalization in final layers\n",
    "        self.is_training = tf.placeholder(tf.bool, None)\n",
    "\n",
    "        # Construct model\n",
    "        dbn_forward_pass_op1 = self.dbn_forward_pass(self.X1, deep_belief_network.autoencoders)\n",
    "        dbn_forward_pass_op2 = self.dbn_forward_pass(self.X2, deep_belief_network.autoencoders)\n",
    "        X = tf.concat([dbn_forward_pass_op1, dbn_forward_pass_op2], axis = 1)\n",
    "        input_X = X\n",
    "        for i in range(len(fin_layer_sizes) - 1):\n",
    "            with tf.variable_scope('fin_forward_pass_op_' + str(i + 1)):\n",
    "                fin_weights = self.fin_weights[i]\n",
    "                fin_biases = self.fin_biases[i]\n",
    "                input_X = self.fin_forward_pass(input_X, fin_weights, fin_biases, True, tf.nn.relu)\n",
    "        fin_weights = self.fin_weights[-1]\n",
    "        fin_biases = self.fin_biases[-1]\n",
    "        with tf.variable_scope('fin_forward_pass_op_' + str(len(fin_layer_sizes))):\n",
    "            self.fin_forward_pass_op = self.fin_forward_pass(input_X, fin_weights, fin_biases, True)\n",
    "        \n",
    "        print(\"The Siamese Network Data Flow Graph is initialized!\")\n",
    "        \n",
    "    # Batch Normalization with population parameters (non-training)\n",
    "    def _pop_batch_norm(self, x, pop_mean, pop_var, offset, scale):\n",
    "            return tf.nn.batch_normalization(x, pop_mean, pop_var, offset, scale, 1e-6)\n",
    "\n",
    "    # Batch Normalization with batch parameters (training)\n",
    "    def _batch_norm(self, x, pop_mean, pop_var, mean, var, offset, scale):\n",
    "        decay = 0.99\n",
    "\n",
    "        dependency_1 = tf.assign(pop_mean, pop_mean * decay + mean * (1 - decay))\n",
    "        dependency_2 = tf.assign(pop_var, pop_var * decay + var * (1 - decay))\n",
    "\n",
    "        with tf.control_dependencies([dependency_1, dependency_2]):\n",
    "            return tf.nn.batch_normalization(x, mean, var, offset, scale, 1e-6)\n",
    "\n",
    "    # Batch Normalization\n",
    "    def _batch_normalize(self, x, axes):\n",
    "        depth = x.shape[-1]\n",
    "        mean, var = tf.nn.moments(x, axes = axes)\n",
    "\n",
    "        var_init = tf.constant_initializer(0.0)\n",
    "        offset = tf.get_variable('offset', [depth], tf.float32, var_init)\n",
    "        var_init = tf.constant_initializer(1.0)\n",
    "        scale = tf.get_variable('scale', [depth], tf.float32, var_init)\n",
    "\n",
    "        pop_mean = tf.get_variable('pop_mean', [depth], initializer = tf.zeros_initializer(), trainable = False)\n",
    "        pop_var = tf.get_variable('pop_var', [depth], initializer = tf.ones_initializer(), trainable = False)\n",
    "\n",
    "        return tf.cond(\n",
    "            self.is_training,\n",
    "            lambda: self._batch_norm(x, pop_mean, pop_var, mean, var, offset, scale),\n",
    "            lambda: self._pop_batch_norm(x, pop_mean, pop_var, offset, scale)\n",
    "        )    \n",
    "    \n",
    "    # Pass the input through the Deep Belief Network\n",
    "    def dbn_forward_pass(self, x, autoencoders):\n",
    "\n",
    "        output = x\n",
    "\n",
    "        for i, autoencoder in enumerate(autoencoders):\n",
    "            with tf.variable_scope('Autoencoder_' + str(i + 1)):\n",
    "                with tf.variable_scope('encoder_op', reuse = True):\n",
    "                    output = autoencoder.encoder(output, True)\n",
    "\n",
    "        return output\n",
    "\n",
    "    # Building final layers: pass the input through the layers with given activation functions\n",
    "    def fin_forward_pass(self, x, weights, biases, normalize = False, activation_function = None):\n",
    "        activation = tf.add(tf.matmul(x, weights), biases)\n",
    "\n",
    "        # Batch Normalization\n",
    "        if normalize:\n",
    "            activation = self._batch_normalize(activation, [0])\n",
    "\n",
    "        return activation_function(activation) if callable(activation_function) else activation\n",
    "    \n",
    "    # Evaluate the Siamese Network\n",
    "    def evaluate(self, sess, X1, X2):\n",
    "        \n",
    "        feed_dict = {self.X1: X1, self.X2: X2, self.is_training: False}\n",
    "        for is_training in self.is_training_list:\n",
    "            feed_dict[is_training] = False\n",
    "        \n",
    "        return sess.run(self.fin_forward_pass_op, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class that defines the behavior of the Minimax Algorithm\n",
    "# with comparison-based alpha-beta search\n",
    "class Minimax(object):\n",
    "    \n",
    "    def __init__(self, sess, deep_chess, deep_chess_data):\n",
    "        \n",
    "        self.sess = sess # tensorflow session\n",
    "        self.deep_chess = deep_chess # heuristic function\n",
    "        self.avg = deep_chess_data.avg # population average for input normalization\n",
    "        self.std = deep_chess_data.std # population standard deviation for input normalization\n",
    "    \n",
    "    # Converts the chess.Board representation of the position\n",
    "    # to a binary bit-string representation called bitboard.\n",
    "    def _normalized_bitboard(self, board):\n",
    "        \n",
    "        # binary bit-string\n",
    "        bitboard = np.zeros(773, dtype=bool)\n",
    "\n",
    "        # every piece on the board gets its bit-representation\n",
    "        piece_map = board.piece_map()\n",
    "        for square in piece_map.keys():\n",
    "            piece = piece_map[square]\n",
    "            color = int(piece.color)\n",
    "            piece_type = piece.piece_type\n",
    "            index = (1 - color) * 6 * 64 + (piece_type - 1) * 64 + square\n",
    "            bitboard[index] = 1\n",
    "\n",
    "        # side to move\n",
    "        bitboard[768] = int(board.turn)\n",
    "\n",
    "        # castling rights\n",
    "        bitboard[769] = int(board.has_kingside_castling_rights(chess.WHITE))\n",
    "        bitboard[770] = int(board.has_queenside_castling_rights(chess.WHITE))\n",
    "        bitboard[771] = int(board.has_kingside_castling_rights(chess.BLACK))\n",
    "        bitboard[772] = int(board.has_queenside_castling_rights(chess.BLACK))\n",
    "\n",
    "        # normalize the bitboard representation\n",
    "        bitboard = (bitboard - self.avg) / self.std\n",
    "        \n",
    "        return np.reshape(bitboard, (1, 773))\n",
    "    \n",
    "    # Fail-hard alpha-beta algorithm (max player)\n",
    "    def alpha_beta_max(self, board, alpha_pos, alpha_move, beta_pos, beta_move, depth):\n",
    "        \n",
    "        # Return the normalized bitboard representation when\n",
    "        # the node is a final one or the depth limit is reached\n",
    "        if depth == 0 or board.is_game_over():\n",
    "            \n",
    "            return self._normalized_bitboard(board), None\n",
    "\n",
    "        # Copy the board\n",
    "        child_board = board.copy()\n",
    "        \n",
    "        # Randomize legal moves\n",
    "        legal_moves = random.sample(list(board.legal_moves), len(list(board.legal_moves)))\n",
    "\n",
    "        # For every legal move,\n",
    "        for move in legal_moves:\n",
    "            \n",
    "            # Make the move on the copy\n",
    "            child_board.push(move)\n",
    "\n",
    "            # Get the result of the move of the min player\n",
    "            pos, _ = self.alpha_beta_min(child_board, alpha_pos, alpha_move, beta_pos, beta_move, depth - 1)\n",
    "            \n",
    "            # If the resulting position is better than the beta position, return the\n",
    "            # beta position which is the least best position for the max player that\n",
    "            # the min player is assured of. This represents fail-hard beta-cutoff.\n",
    "            # Having a guaranteed worse outcome for the max player, the min player\n",
    "            # won't enter this node since the max player has at least one move in\n",
    "            # this node with an outcome that dominates beta position. Note: None\n",
    "            # corresponds to an infinitely good outcome for the max player when\n",
    "            # assigned to the beta position.\n",
    "            if beta_pos is not None:\n",
    "                comparison = np.squeeze(self.deep_chess.evaluate(self.sess, pos, beta_pos))\n",
    "                if comparison[0] >= comparison[1]:\n",
    "                    return beta_pos, beta_move\n",
    "\n",
    "            # If the resulting position is better than the alpha position, assign it to\n",
    "            # to the alpha position which is the least worst position for the max player\n",
    "            # that the max player is assured of. After entering this node, the max player\n",
    "            # can make at least this move that results in a better position than the alpha\n",
    "            # position. Hence, the resulting position is the new guaranteed least worst case.\n",
    "            # Note: None corresponds to an infinitely bad outcome for the max player when\n",
    "            # assigned to the alpha position.\n",
    "            if alpha_pos is None:\n",
    "                \n",
    "                alpha_pos = pos\n",
    "                alpha_move = move\n",
    "            else:\n",
    "                comparison = np.squeeze(self.deep_chess.evaluate(self.sess, pos, alpha_pos))\n",
    "                if comparison[0] > comparison[1]:\n",
    "                    alpha_pos = pos\n",
    "                    alpha_move = move\n",
    "\n",
    "            # Unmake the move\n",
    "            child_board = board.copy()\n",
    "\n",
    "        # Return the alpha position (and the corresponding move) as\n",
    "        # it is the guaranteed worst-case scenario for the max player.\n",
    "        return alpha_pos, alpha_move\n",
    "        \n",
    "    # Fail-hard alpha-beta algorithm (min player)\n",
    "    def alpha_beta_min(self, board, alpha_pos, alpha_move, beta_pos, beta_move, depth):\n",
    "            \n",
    "        # Return the normalized bitboard representation when\n",
    "        # the node is a final one or the depth limit is reached\n",
    "        if depth == 0 or board.is_game_over():\n",
    "            \n",
    "            return self._normalized_bitboard(board), None\n",
    "\n",
    "         # Copy the board\n",
    "        child_board = board.copy()\n",
    "        \n",
    "        # Randomize legal moves\n",
    "        legal_moves = random.sample(list(board.legal_moves), len(list(board.legal_moves)))\n",
    "\n",
    "        # For every legal move,\n",
    "        for move in legal_moves:\n",
    "            \n",
    "            # Make the move on the copy\n",
    "            child_board.push(move)\n",
    "            \n",
    "            # Get the result of the move of the max player\n",
    "            pos, _ = self.alpha_beta_max(child_board, alpha_pos, alpha_move, beta_pos, beta_move, depth - 1)\n",
    "            \n",
    "            # If the resulting position is worse than the alpha position, return the\n",
    "            # alpha position which is the least worst position for the max player that\n",
    "            # the max player is assured of. This represents fail-hard alpha-cutoff.\n",
    "            # Having a guaranteed better outcome for the itself, the max player\n",
    "            # won't enter this node since the min player has at least one move in\n",
    "            # this node with an outcome that is worse than the alpha position.\n",
    "            # Note: None corresponds to an infinitely bad outcome for the max player\n",
    "            # when assigned to the alpha position.\n",
    "            if alpha_pos is not None:\n",
    "                comparison = np.squeeze(self.deep_chess.evaluate(self.sess, pos, alpha_pos))\n",
    "                if comparison[0] <= comparison[1]:\n",
    "                    return alpha_pos, alpha_move\n",
    "\n",
    "            # If the resulting position is worse than the beta position, assign it to\n",
    "            # to the beta position which is the least best position for the max player\n",
    "            # that the min player is assured of. After entering this node, the min player\n",
    "            # can make at least this move that results in a worse position for the max player\n",
    "            # than the beta position. Hence, the resulting position is the new guaranteed\n",
    "            # least worst case. Note: None corresponds to an infinitely good outcome for\n",
    "            # the max player when assigned to the beta position.\n",
    "            if beta_pos is None:\n",
    "                beta_pos = pos\n",
    "                beta_move = move\n",
    "            else:\n",
    "                comparison = np.squeeze(self.deep_chess.evaluate(self.sess, pos, beta_pos))\n",
    "                if comparison[0] < comparison[1]:\n",
    "                    beta_pos = pos\n",
    "                    beta_move = move\n",
    "\n",
    "            # Unmake the move\n",
    "            child_board = board.copy()\n",
    "\n",
    "        # Return the beta position (and the corresponding move) as\n",
    "        # it is the guaranteed worst-case scenario for the min player.\n",
    "        return beta_pos, beta_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chess Playing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class that defines the behavior\n",
    "# of the Chess Playing Environment\n",
    "class ChessPlayingEnvironment(object):\n",
    "    \n",
    "    def __init__(self, minimax, depth):\n",
    "    \n",
    "        self.board = chess.Board() # initialize a new playing board\n",
    "        self.minimax = minimax # Minimax Algorithm\n",
    "        self.depth = depth # depth limit for the Minimax Algorithm\n",
    "\n",
    "    # method for game simulation\n",
    "    def play(self):\n",
    "        \n",
    "        # new game flag\n",
    "        new_game = True\n",
    "        \n",
    "        # check if there is an abandoned game\n",
    "        while True:\n",
    "            try:\n",
    "                # when an abandoned game is detected,\n",
    "                # ask if the player wants to continue\n",
    "                move = self.board.pop()\n",
    "                self.board.push(move)\n",
    "                if not self.board.is_game_over():\n",
    "                    answer = input(\"Do you want to continue the previously abandoned game? \\n\")\n",
    "                    if answer in ['Yes', 'yes']:\n",
    "                        # if yes, change the new game flag\n",
    "                        new_game = False\n",
    "                        # clear the output of the cell\n",
    "                        clear_output(wait = True)\n",
    "                        # display the playing board\n",
    "                        display(self.board)\n",
    "                        break\n",
    "                    elif answer in ['No', 'no']:\n",
    "                        # if not, initialize a new playing board\n",
    "                        self.board = chess.Board()\n",
    "                        # clear the output of the cell\n",
    "                        clear_output(wait = True)\n",
    "                        break\n",
    "                    else:\n",
    "                        raise ValueError\n",
    "                else:\n",
    "                    clear_output(wait = True)\n",
    "                    self.board = chess.Board()\n",
    "            except IndexError:\n",
    "                break\n",
    "            except ValueError:\n",
    "                # clear the output of the cell\n",
    "                clear_output(wait = True)\n",
    "                print(\"Please enter a valid answer!\")\n",
    "        \n",
    "        # get player's piece preferences\n",
    "        while new_game:\n",
    "            try:\n",
    "                player = input(\"Who plays with white pieces? DeepChess or you? \\n\")\n",
    "                if player in ['me', 'Me', 'i', 'I']:\n",
    "                    # DeepChess is not playing with white pieces\n",
    "                    self.white = False\n",
    "                    # it is the player's turn to make a move\n",
    "                    self.my_turn = True\n",
    "                elif player in ['Deep Chess', 'deep chess', 'DeepChess', 'Deep chess', 'deepchess', 'Deepchess']:\n",
    "                    # DeepChess is playing with white pieces\n",
    "                    self.white = True\n",
    "                    # it is not the player's turn to make a move\n",
    "                    self.my_turn = False\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            except ValueError:\n",
    "                # clear the output of the cell\n",
    "                clear_output(wait = True)\n",
    "                print(\"Please enter a valid answer!\")\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        # display the playing board\n",
    "        clear_output(wait = True)\n",
    "        # clear the output of the cell\n",
    "        display(self.board)\n",
    "\n",
    "        # abandoned game flag\n",
    "        abandoned = False \n",
    "        \n",
    "        # main game loop: as long as the game is not over or abandoned,\n",
    "        while (not abandoned) and (not self.board.is_game_over()):\n",
    "            # if it is not the player's turn\n",
    "            if not self.my_turn:\n",
    "                print(\"DeepChess is thinking ...\")\n",
    "                if self.white:\n",
    "                    # run alpha_beta_max to get DeepChess' move when its playing with whites\n",
    "                    _, move = self.minimax.alpha_beta_max(self.board, None, None, None, None, self.depth)\n",
    "                else:\n",
    "                    # run alpha_beta_min to get DeepChess' move when its playing with blacks\n",
    "                    _, move = self.minimax.alpha_beta_min(self.board, None, None, None, None, self.depth)\n",
    "            # if it is the player's turn\n",
    "            else:\n",
    "                # get the player's move\n",
    "                while True:\n",
    "                    try:\n",
    "                        move = input(\"Your move: \")\n",
    "                        if move in ['Quit', 'quit']:\n",
    "                            # set the abandoned game flag to\n",
    "                            # True when the player quits\n",
    "                            abandoned = True\n",
    "                            # clear the output of the cell\n",
    "                            clear_output(wait = True)\n",
    "                            # display the playing board\n",
    "                            display(self.board)\n",
    "                            print(\"The game was abandoned.\")\n",
    "                        else:\n",
    "                            # check if the move is a legal move\n",
    "                            move = chess.Move.from_uci(move)\n",
    "                            if move not in self.board.legal_moves:\n",
    "                                raise ValueError\n",
    "                    except ValueError:\n",
    "                        # clear the output of the cell\n",
    "                        clear_output(wait = True)\n",
    "                        # display the playing board\n",
    "                        display(self.board)\n",
    "                        print(\"Please enter a legal move!\")\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "            # as long as the game is not over or abandoned,\n",
    "            if (not abandoned) and (not self.board.is_game_over()):\n",
    "                # change the turn\n",
    "                self.my_turn = not self.my_turn\n",
    "                # update the board\n",
    "                self.board.push(move)\n",
    "                # clear the output of the cell\n",
    "                clear_output(wait = True)\n",
    "                # display the playing board\n",
    "                display(self.board)\n",
    "        # end game conditions\n",
    "        if self.board.is_checkmate():\n",
    "            if not self.my_turn:\n",
    "                print(\"You won!\")\n",
    "            else:\n",
    "                print(\"You lost!\")\n",
    "        elif self.board.is_stalemate() or self.board.is_insufficient_material():\n",
    "            print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class instances and TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Deep Chess Data\n",
    "deep_chess_data = DeepChessData('./data/win_data.npz', './data/loss_data.npz')\n",
    "\n",
    "# Create Pos2Vec and DeepChess instances\n",
    "pos_2_vec = DeepBeliefNetwork(dbn_layer_sizes = [773, 100, 100, 100])\n",
    "deep_chess = SiameseNetwork(deep_belief_network = pos_2_vec, fin_layer_sizes = [100, 100, 2])\n",
    "\n",
    "# Instantiate a tf session and a model saver\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours = 2)\n",
    "\n",
    "# Initialize the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Restore the model\n",
    "saver.restore(sess, './model/model.ckpt')\n",
    "\n",
    "# Create a Minimax instance\n",
    "minimax = Minimax(sess, deep_chess, deep_chess_data)\n",
    "\n",
    "# Create a ChessPlayingEnvironment instance\n",
    "chess_playing_environment = ChessPlayingEnvironment(minimax, depth = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play\n",
    "#### Enter your move as the concatenation of the coordinate of the piece and the coordinate of the square that you would like to move the piece to. For example, to move the white pawn on 'e2' to 'e4', write 'e2e4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play against DeepChess\n",
    "chess_playing_environment.play()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
